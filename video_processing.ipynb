{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/arnaav/anaconda3/lib/python3.11/site-packages (8.2.41)\n",
      "Collecting ultralytics\n",
      "  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/93/18/048166fe59600c8cec5857df75d7f9a45aef2c598d324782b05b1d6660c3/ultralytics-8.2.42-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.2.42-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m91.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.16.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (8.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arnaav/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.2.42-py3-none-any.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.0/793.0 kB\u001b[0m \u001b[31m366.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.2.41\n",
      "    Uninstalling ultralytics-8.2.41:\n",
      "      Successfully uninstalled ultralytics-8.2.41\n",
      "Successfully installed ultralytics-8.2.42\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom YOLOv5 model\n",
    "model_path = 'best.pt'  # Update with your model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/arnaav/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-6-24 Python-3.11.5 torch-2.1.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, object_detector, model, kernel, roi_coords):\n",
    "    # Convert frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform inference (Placeholder - replace with actual inference code)\n",
    "    results = model(frame_rgb)  # Replace with actual model inference\n",
    "\n",
    "    # Extract bounding box coordinates and calculate center points and heights\n",
    "    max_area = 0\n",
    "    max_box = None\n",
    "    for result in results.xyxy[0]:  # xyxy format\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = result.tolist()\n",
    "        area = (x_max - x_min) * (y_max - y_min)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_box = (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    if max_box:\n",
    "        x_min, y_min, x_max, y_max = [int(coord) for coord in max_box]\n",
    "        center_x = (x_min + x_max) / 2\n",
    "        center_y = (y_min + y_max) / 2\n",
    "        height = y_max - y_min\n",
    "\n",
    "        return (center_x, center_y), height, frame_rgb\n",
    "\n",
    "    return None, None, frame_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bg_subtraction(frame, object_detector, kernel, roi_coords):\n",
    "    roi_x, roi_y, roi_width, roi_height = roi_coords\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Apply the background subtractor to get the mask\n",
    "    mask = object_detector.apply(blurred_frame)\n",
    "\n",
    "    # Apply morphological operations to reduce noise\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Extract the ROI from the mask\n",
    "    roi_mask = mask[roi_y:roi_y + roi_height, roi_x:roi_x + roi_width]\n",
    "\n",
    "    # Count the number of non-zero pixels in the ROI mask\n",
    "    movement = cv2.countNonZero(roi_mask)\n",
    "\n",
    "    return movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_state(height_diff, movement_detected, threshold1, threshold2):\n",
    "    if height_diff > threshold2 and movement_detected:\n",
    "        return 'working'\n",
    "    elif height_diff > threshold1 and movement_detected:\n",
    "        return 'moving'\n",
    "    else:\n",
    "        return 'idle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame(frame, center_point, height, state, movement_detected, text_x):\n",
    "    center_x, center_y = center_point\n",
    "\n",
    "    # Annotate the state and probabilities on the frame\n",
    "    cv2.putText(frame, f'Movement: {movement_detected}', (text_x, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, f'State: {state}', (text_x, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "    # Draw the center point on the frame\n",
    "    cv2.circle(frame, (int(center_x), int(center_y)), 5, (0, 0, 255), -1)\n",
    "    # Annotate the height on the frame\n",
    "    cv2.putText(frame, f'Height: {int(height)}', (int(center_x), int(center_y - 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(center_points, heights, height_diffs):\n",
    "    if center_points:\n",
    "        tracked_centers_x = [pt[0] for pt in center_points]\n",
    "        tracked_centers_y = [pt[1] for pt in center_points]\n",
    "        tracked_heights = heights\n",
    "        tracked_height_diffs = height_diffs\n",
    "\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Plotting center points\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(tracked_centers_x, tracked_centers_y, marker='o')\n",
    "        plt.title('Movement of Center Points')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Center Point (x, y)')\n",
    "\n",
    "        # Plotting heights\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(tracked_heights, marker='o')\n",
    "        plt.title('Heights of Bounding Boxes')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Height')\n",
    "\n",
    "        # Plotting height differences\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(tracked_height_diffs, marker='o')\n",
    "        plt.title('Height Differences')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Height Difference')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_on_video(video_path, output_video_path, threshold1, threshold2,model, movement_threshold=8000):\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the width and height of the frames\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "    # List to store the center points and heights\n",
    "    center_points = []\n",
    "    heights = []\n",
    "    height_diffs = []\n",
    "\n",
    "    # Define the ROI coordinates (x, y, width, height)\n",
    "    roi_coords = (250, 200, 500, frame_height - 200)\n",
    "\n",
    "    # Create the background subtractor object\n",
    "    object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    # Define kernel for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "    initial_height = None  # Variable to store the initial height\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        center_point, height, frame_rgb = process_frame(frame, object_detector,model, kernel, roi_coords)\n",
    "\n",
    "        if center_point:\n",
    "            if initial_height is None:\n",
    "                initial_height = height\n",
    "\n",
    "            center_points.append(center_point)\n",
    "            heights.append(height)\n",
    "\n",
    "            height_diff = abs(height - initial_height)\n",
    "            height_diffs.append(height_diff)\n",
    "\n",
    "            movement = apply_bg_subtraction(frame, object_detector, kernel, roi_coords)\n",
    "            movement_detected = movement > movement_threshold\n",
    "\n",
    "            state = determine_state(height_diff, movement_detected, threshold1, threshold2)\n",
    "            max_height_diff = max(height_diffs) if height_diffs else 1\n",
    "\n",
    "            text_x = frame_width - 200  # Adjust as needed for positioning\n",
    "            frame = annotate_frame(frame, center_point, height, state, movement_detected, text_x)\n",
    "\n",
    "            # Draw the ROI rectangle on the frame\n",
    "            cv2.rectangle(frame, (roi_coords[0], roi_coords[1]),\n",
    "                          (roi_coords[0] + roi_coords[2], roi_coords[1] + roi_coords[3]),\n",
    "                          (255, 0, 0), 2)\n",
    "\n",
    "        # Write the frame into the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    plot_metrics(center_points, heights, height_diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "test_model_on_video('input_video/video2.mp4','output_video/processed-video2.mp4',2,10,model,7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
